{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vB39P5f2uNRw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, random_split, Subset, Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "sYAjJWTuuXOk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "0is-dDG0vfXN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsPAP3Oevmae",
        "outputId": "f03110ac-7fb5-4509-dbf7-0de4bee52b3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"drive/MyDrive/Enappsys Data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY7Rj1c4xc_W",
        "outputId": "74a6f876-b9df-4c6c-b47e-28185a35f7c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Enappsys Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import time"
      ],
      "metadata": {
        "id": "2YrzeKCCRhVQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "ZEMC2WXCz30L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an abstract class of the Dataset class in torch module. Modifying it according to the data we require."
      ],
      "metadata": {
        "id": "hEP8bbjqTmIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        \"\"\"\n",
        "        This is extraction step of the data processing\n",
        "        \"\"\"\n",
        "        file_out = pd.read_csv(filename)\n",
        "        x = file_out.iloc[:, :-1].values\n",
        "        y = file_out.iloc[:, -1].values\n",
        "\n",
        "        sc = StandardScaler()\n",
        "        x =  sc.fit_transform(x)\n",
        "\n",
        "        \"\"\"\n",
        "        This is the transformation step of data\n",
        "        \"\"\"\n",
        "        self.X = torch.tensor(x, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vSNPIA6lxnY0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset('train.csv')"
      ],
      "metadata": {
        "id": "Yk_DLEmNSeIi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Can't create the same for test dataset yet. because it doesnt have any **Y** variable"
      ],
      "metadata": {
        "id": "ypSujeW5UAMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset is created.Now we will create the DataLoader to be fed in the network. This is the Loading step of the data. ETL is completed after this"
      ],
      "metadata": {
        "id": "3YSDh3zpTuyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the train/val split\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "-zK18BmlHzc2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z8uXDv_Uns0",
        "outputId": "4722ca67-2c01-4cbd-8da3-0a86979f3d06"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16430"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(train_set))"
      ],
      "metadata": {
        "id": "_tc8OIWQU37A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlQ7Xk-DU6lI",
        "outputId": "ca5992a0-58ce-4168-ebf0-a7b482cfb044"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1387])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAegkNmRVCnQ",
        "outputId": "5000331f-57fd-4cef-ff52-8068755d8b04"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset using data loader and making mini-batches\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_set,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "u2LFt5IBVE7Q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "B5D9jGxZIaIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXiOcUUOIlgP",
        "outputId": "9cda7fa9-6f30-47dc-bdfb-6a7548375c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1387])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_batch.shape"
      ],
      "metadata": {
        "id": "q6933tG-ImUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52709f5e-0d4a-46f2-8d5d-7d6cad2e2542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZSItTnhvfzm",
        "outputId": "7ca4acea-52a8-4a3f-b9a4-2a2b9d910ae0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Feed forward network"
      ],
      "metadata": {
        "id": "vCQKnaAjpj3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=512\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "8QBnlG_rpi5d"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adamax(mlp.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "2rExlIkerNrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mlp.to(device)"
      ],
      "metadata": {
        "id": "qihzay_k-dEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_accs=[]\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # inputs.to(device)\n",
        "      # targets.to(device)\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfsX1NFMriBk",
        "outputId": "db26edac-86ac-4bbb-8cf6-97cb4e8f8d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([30])) that is different to the input size (torch.Size([30, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken for epoch 1 is 3.24\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 3.23\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 4.00\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 3.02\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 3.24\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 3.63\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 4.27\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 3.33\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 3.38\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 4.11\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 3.95\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 3.41\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 3.42\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 4.44\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 3.48\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 3.49\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 3.68\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 4.20\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 3.46\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 3.54\n",
            "Training process has finished. Time taken is 72.49816370010376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "ulmEFfOLCU4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVhfwc-lsM1a",
        "outputId": "e18a2dc5-2109-49e4-95c7-ee175778997b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 4234928.25745252\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 3997192.331822769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 2"
      ],
      "metadata": {
        "id": "X32-sredYYU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=512\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "pIxldKI8YUWb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "J8vEqpuyYUWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_accs=[]\n",
        "\n",
        "epochs=50\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa4c96a-fa2d-4e26-d6c7-3a2c4e17cfb2",
        "id": "bEmx4G5NYUWf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 4.65\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 4.59\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 4.06\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 4.38\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 124730.64620978803\n",
            "time taken for epoch 5 is 5.09\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 4.77\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 5.69\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 4.67\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 4.79\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 129043.04725480318\n",
            "time taken for epoch 10 is 5.76\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 4.71\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 5.10\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 5.28\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 4.61\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 106464.56447823152\n",
            "time taken for epoch 15 is 5.64\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 4.85\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 4.89\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 5.75\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 4.64\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 90868.02714289907\n",
            "time taken for epoch 20 is 5.19\n",
            "Starting epoch 21\n",
            "time taken for epoch 21 is 5.10\n",
            "Starting epoch 22\n",
            "time taken for epoch 22 is 4.67\n",
            "Starting epoch 23\n",
            "time taken for epoch 23 is 5.67\n",
            "Starting epoch 24\n",
            "time taken for epoch 24 is 4.54\n",
            "Starting epoch 25\n",
            "train MSE after epoch 25 is 79284.27639402874\n",
            "time taken for epoch 25 is 4.56\n",
            "Starting epoch 26\n",
            "time taken for epoch 26 is 5.47\n",
            "Starting epoch 27\n",
            "time taken for epoch 27 is 4.64\n",
            "Starting epoch 28\n",
            "time taken for epoch 28 is 4.89\n",
            "Starting epoch 29\n",
            "time taken for epoch 29 is 5.30\n",
            "Starting epoch 30\n",
            "train MSE after epoch 30 is 69847.74168133736\n",
            "time taken for epoch 30 is 4.55\n",
            "Starting epoch 31\n",
            "time taken for epoch 31 is 5.38\n",
            "Starting epoch 32\n",
            "time taken for epoch 32 is 4.90\n",
            "Starting epoch 33\n",
            "time taken for epoch 33 is 4.52\n",
            "Starting epoch 34\n",
            "time taken for epoch 34 is 5.61\n",
            "Starting epoch 35\n",
            "train MSE after epoch 35 is 63166.43867773673\n",
            "time taken for epoch 35 is 4.57\n",
            "Starting epoch 36\n",
            "time taken for epoch 36 is 4.59\n",
            "Starting epoch 37\n",
            "time taken for epoch 37 is 5.55\n",
            "Starting epoch 38\n",
            "time taken for epoch 38 is 4.60\n",
            "Starting epoch 39\n",
            "time taken for epoch 39 is 5.06\n",
            "Starting epoch 40\n",
            "train MSE after epoch 40 is 57615.79672598861\n",
            "time taken for epoch 40 is 5.19\n",
            "Starting epoch 41\n",
            "time taken for epoch 41 is 4.73\n",
            "Starting epoch 42\n",
            "time taken for epoch 42 is 5.64\n",
            "Starting epoch 43\n",
            "time taken for epoch 43 is 4.65\n",
            "Starting epoch 44\n",
            "time taken for epoch 44 is 4.62\n",
            "Starting epoch 45\n",
            "train MSE after epoch 45 is 52813.824766648366\n",
            "time taken for epoch 45 is 5.53\n",
            "Starting epoch 46\n",
            "time taken for epoch 46 is 4.72\n",
            "Starting epoch 47\n",
            "time taken for epoch 47 is 5.01\n",
            "Starting epoch 48\n",
            "time taken for epoch 48 is 5.36\n",
            "Starting epoch 49\n",
            "time taken for epoch 49 is 4.60\n",
            "Starting epoch 50\n",
            "train MSE after epoch 50 is 48571.520035049776\n",
            "time taken for epoch 50 is 5.58\n",
            "Training process has finished. Time taken is 248.91095399856567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901b6027-6a91-486b-c1ad-5119bbab9727",
        "id": "x-rXmFwRYUWg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 11635.30885145958\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 61558.17472441997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUFAB-f5gqSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3"
      ],
      "metadata": {
        "id": "wb2RGorKkfez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=512\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "RNMTh0n9keME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.002, weight_decay=0.002)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "-wo6FO0jkeMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "epochs=50\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1883b5-12c6-44e9-9481-a231748107a8",
        "id": "l3yzXREKkeMI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 3.58\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 3.06\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 3.08\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 3.30\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 115756.8885570178\n",
            "time taken for epoch 5 is 3.50\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 3.09\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 3.09\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 3.44\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 3.40\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 93728.80211051911\n",
            "time taken for epoch 10 is 3.08\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 3.07\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 3.40\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 3.40\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 3.10\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 81957.79833478681\n",
            "time taken for epoch 15 is 3.09\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 3.48\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 3.24\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 3.04\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 3.09\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 70383.88453393982\n",
            "time taken for epoch 20 is 3.50\n",
            "Starting epoch 21\n",
            "time taken for epoch 21 is 3.28\n",
            "Starting epoch 22\n",
            "time taken for epoch 22 is 3.13\n",
            "Starting epoch 23\n",
            "time taken for epoch 23 is 3.19\n",
            "Starting epoch 24\n",
            "time taken for epoch 24 is 3.69\n",
            "Starting epoch 25\n",
            "train MSE after epoch 25 is 60185.216055593155\n",
            "time taken for epoch 25 is 3.11\n",
            "Starting epoch 26\n",
            "time taken for epoch 26 is 3.14\n",
            "Starting epoch 27\n",
            "time taken for epoch 27 is 3.12\n",
            "Starting epoch 28\n",
            "time taken for epoch 28 is 3.67\n",
            "Starting epoch 29\n",
            "time taken for epoch 29 is 3.11\n",
            "Starting epoch 30\n",
            "train MSE after epoch 30 is 53683.420676404596\n",
            "time taken for epoch 30 is 3.08\n",
            "Starting epoch 31\n",
            "time taken for epoch 31 is 3.09\n",
            "Starting epoch 32\n",
            "time taken for epoch 32 is 3.66\n",
            "Starting epoch 33\n",
            "time taken for epoch 33 is 3.08\n",
            "Starting epoch 34\n",
            "time taken for epoch 34 is 3.10\n",
            "Starting epoch 35\n",
            "train MSE after epoch 35 is 48337.89908463651\n",
            "time taken for epoch 35 is 3.15\n",
            "Starting epoch 36\n",
            "time taken for epoch 36 is 3.68\n",
            "Starting epoch 37\n",
            "time taken for epoch 37 is 3.02\n",
            "Starting epoch 38\n",
            "time taken for epoch 38 is 3.13\n",
            "Starting epoch 39\n",
            "time taken for epoch 39 is 3.13\n",
            "Starting epoch 40\n",
            "train MSE after epoch 40 is 43822.51446278196\n",
            "time taken for epoch 40 is 3.64\n",
            "Starting epoch 41\n",
            "time taken for epoch 41 is 3.09\n",
            "Starting epoch 42\n",
            "time taken for epoch 42 is 3.13\n",
            "Starting epoch 43\n",
            "time taken for epoch 43 is 3.16\n",
            "Starting epoch 44\n",
            "time taken for epoch 44 is 3.64\n",
            "Starting epoch 45\n",
            "train MSE after epoch 45 is 40232.753868885266\n",
            "time taken for epoch 45 is 3.12\n",
            "Starting epoch 46\n",
            "time taken for epoch 46 is 3.12\n",
            "Starting epoch 47\n",
            "time taken for epoch 47 is 3.15\n",
            "Starting epoch 48\n",
            "time taken for epoch 48 is 3.61\n",
            "Starting epoch 49\n",
            "time taken for epoch 49 is 3.10\n",
            "Starting epoch 50\n",
            "train MSE after epoch 50 is 36975.770651886065\n",
            "time taken for epoch 50 is 3.10\n",
            "Training process has finished. Time taken is 162.5033667087555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1ae5ca-44e1-4f51-8d30-18e70895cc44",
        "id": "nj7cM9GpkeMJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 13765.324907054272\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 56628.916922751094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2_-KOLGikeMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 4"
      ],
      "metadata": {
        "id": "EK2_JdhwvHP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=512\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "XOdH0U4KvFum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.002, weight_decay=0.005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "iwy0xvAgvFuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=80\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbf891e-f114-4755-e67f-7791419b82dc",
        "id": "AY4O6YxTvFuo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 9.62\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 9.56\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 9.69\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 9.40\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 14819.719137506918\n",
            "time taken for epoch 5 is 10.20\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 10.12\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 9.88\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 10.02\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 10.75\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 15348.661362072591\n",
            "time taken for epoch 10 is 10.78\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 10.76\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 10.08\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 10.42\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 10.55\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 14955.012152457894\n",
            "time taken for epoch 15 is 10.21\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 9.63\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 10.17\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 10.63\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 10.11\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 14263.343047062102\n",
            "time taken for epoch 20 is 9.08\n",
            "Starting epoch 21\n",
            "time taken for epoch 21 is 9.42\n",
            "Starting epoch 22\n",
            "time taken for epoch 22 is 9.71\n",
            "Starting epoch 23\n",
            "time taken for epoch 23 is 9.70\n",
            "Starting epoch 24\n",
            "time taken for epoch 24 is 9.23\n",
            "Starting epoch 25\n",
            "train MSE after epoch 25 is 12518.817404459172\n",
            "time taken for epoch 25 is 9.98\n",
            "Starting epoch 26\n",
            "time taken for epoch 26 is 9.88\n",
            "Starting epoch 27\n",
            "time taken for epoch 27 is 9.33\n",
            "Starting epoch 28\n",
            "time taken for epoch 28 is 9.09\n",
            "Starting epoch 29\n",
            "time taken for epoch 29 is 9.38\n",
            "Starting epoch 30\n",
            "train MSE after epoch 30 is 11837.707478886769\n",
            "time taken for epoch 30 is 8.75\n",
            "Starting epoch 31\n",
            "time taken for epoch 31 is 8.83\n",
            "Starting epoch 32\n",
            "time taken for epoch 32 is 9.13\n",
            "Starting epoch 33\n",
            "time taken for epoch 33 is 8.40\n",
            "Starting epoch 34\n",
            "time taken for epoch 34 is 8.92\n",
            "Starting epoch 35\n",
            "train MSE after epoch 35 is 11486.509773306283\n",
            "time taken for epoch 35 is 9.05\n",
            "Starting epoch 36\n",
            "time taken for epoch 36 is 8.13\n",
            "Starting epoch 37\n",
            "time taken for epoch 37 is 8.88\n",
            "Starting epoch 38\n",
            "time taken for epoch 38 is 9.13\n",
            "Starting epoch 39\n",
            "time taken for epoch 39 is 8.36\n",
            "Starting epoch 40\n",
            "train MSE after epoch 40 is 10712.24883286566\n",
            "time taken for epoch 40 is 9.37\n",
            "Starting epoch 41\n",
            "time taken for epoch 41 is 9.29\n",
            "Starting epoch 42\n",
            "time taken for epoch 42 is 8.82\n",
            "Starting epoch 43\n",
            "time taken for epoch 43 is 9.58\n",
            "Starting epoch 44\n",
            "time taken for epoch 44 is 9.55\n",
            "Starting epoch 45\n",
            "train MSE after epoch 45 is 10403.688221193419\n",
            "time taken for epoch 45 is 8.81\n",
            "Starting epoch 46\n",
            "time taken for epoch 46 is 8.96\n",
            "Starting epoch 47\n",
            "time taken for epoch 47 is 9.42\n",
            "Starting epoch 48\n",
            "time taken for epoch 48 is 9.07\n",
            "Starting epoch 49\n",
            "time taken for epoch 49 is 8.92\n",
            "Starting epoch 50\n",
            "train MSE after epoch 50 is 10356.420874977784\n",
            "time taken for epoch 50 is 9.74\n",
            "Starting epoch 51\n",
            "time taken for epoch 51 is 9.70\n",
            "Starting epoch 52\n",
            "time taken for epoch 52 is 8.99\n",
            "Starting epoch 53\n",
            "time taken for epoch 53 is 9.91\n",
            "Starting epoch 54\n",
            "time taken for epoch 54 is 10.50\n",
            "Starting epoch 55\n",
            "train MSE after epoch 55 is 10259.83733933282\n",
            "time taken for epoch 55 is 10.26\n",
            "Starting epoch 56\n",
            "time taken for epoch 56 is 10.02\n",
            "Starting epoch 57\n",
            "time taken for epoch 57 is 10.72\n",
            "Starting epoch 58\n",
            "time taken for epoch 58 is 10.85\n",
            "Starting epoch 59\n",
            "time taken for epoch 59 is 10.86\n",
            "Starting epoch 60\n",
            "train MSE after epoch 60 is 9818.543878185254\n",
            "time taken for epoch 60 is 11.51\n",
            "Starting epoch 61\n",
            "time taken for epoch 61 is 11.22\n",
            "Starting epoch 62\n",
            "time taken for epoch 62 is 11.77\n",
            "Starting epoch 63\n",
            "time taken for epoch 63 is 12.13\n",
            "Starting epoch 64\n",
            "time taken for epoch 64 is 11.75\n",
            "Starting epoch 65\n",
            "train MSE after epoch 65 is 9436.526120593191\n",
            "time taken for epoch 65 is 11.62\n",
            "Starting epoch 66\n",
            "time taken for epoch 66 is 11.89\n",
            "Starting epoch 67\n",
            "time taken for epoch 67 is 11.77\n",
            "Starting epoch 68\n",
            "time taken for epoch 68 is 11.40\n",
            "Starting epoch 69\n",
            "time taken for epoch 69 is 11.19\n",
            "Starting epoch 70\n",
            "train MSE after epoch 70 is 9057.697205504483\n",
            "time taken for epoch 70 is 11.41\n",
            "Starting epoch 71\n",
            "time taken for epoch 71 is 11.81\n",
            "Starting epoch 72\n",
            "time taken for epoch 72 is 11.83\n",
            "Starting epoch 73\n",
            "time taken for epoch 73 is 12.06\n",
            "Starting epoch 74\n",
            "time taken for epoch 74 is 12.58\n",
            "Starting epoch 75\n",
            "train MSE after epoch 75 is 8716.59591905571\n",
            "time taken for epoch 75 is 12.79\n",
            "Starting epoch 76\n",
            "time taken for epoch 76 is 12.50\n",
            "Starting epoch 77\n",
            "time taken for epoch 77 is 12.73\n",
            "Starting epoch 78\n",
            "time taken for epoch 78 is 12.99\n",
            "Starting epoch 79\n",
            "time taken for epoch 79 is 13.01\n",
            "Starting epoch 80\n",
            "train MSE after epoch 80 is 8356.101141078798\n",
            "time taken for epoch 80 is 13.31\n",
            "Training process has finished. Time taken is 821.6343116760254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fbcfaa-3386-428b-b226-060e4c7ae0b0",
        "id": "d-xkuvptvFup"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 2605.475234472611\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 47154.73558715159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4CGatwU_0u6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 5"
      ],
      "metadata": {
        "id": "pO50wvpOFQ16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=512\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "U9-SPhVQFQ2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.RMSprop(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.001,\n",
        "#                      step_size_up=2000, mode='triangular2')\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "Id-dsr2KFQ2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72299eb5-5518-4a83-8023-70dbb55a5fb1",
        "id": "LUR3GGuUFQ2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 3.35\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 3.99\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 3.80\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 3.22\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 3.18\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 4.01\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 3.70\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 3.20\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 3.23\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 4.07\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 3.65\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 3.21\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 3.16\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 4.14\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 3.52\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 3.24\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 3.23\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 4.27\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 3.48\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 3.31\n",
            "Training process has finished. Time taken is 70.97157430648804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2e2f6f-c834-4e87-e104-6d12dfd23e74",
        "id": "jzLDbXyXFQ2g"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 50450.149413284016\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 103541.2527976258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  # mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  # train_mse.append(mse)"
      ],
      "metadata": {
        "id": "5PxLca8JF6P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfZCMUzeiOcX",
        "outputId": "738f4fac-b476-4dba-e3dc-d8d4efa3460c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.1676e+03],\n",
              "        [ 2.0682e+01],\n",
              "        [ 2.8995e+01],\n",
              "        [ 3.1990e+00],\n",
              "        [ 9.0011e+01],\n",
              "        [ 1.3886e+00],\n",
              "        [ 3.3306e+03],\n",
              "        [ 1.0512e+01],\n",
              "        [-4.3013e+00],\n",
              "        [ 6.7146e+03],\n",
              "        [-1.1334e+01],\n",
              "        [-5.8078e+00],\n",
              "        [ 1.2085e+01],\n",
              "        [ 7.3597e+03],\n",
              "        [-5.5015e+00],\n",
              "        [ 4.1414e+00],\n",
              "        [ 4.4336e+02],\n",
              "        [ 4.8140e+02],\n",
              "        [ 8.3415e+02],\n",
              "        [ 5.0055e+00],\n",
              "        [ 2.6227e+01],\n",
              "        [ 1.6758e+03],\n",
              "        [-7.4917e+00],\n",
              "        [ 6.1105e+00],\n",
              "        [ 6.7051e+02],\n",
              "        [ 5.2950e+03],\n",
              "        [ 4.5567e+01],\n",
              "        [ 8.8066e+02],\n",
              "        [ 5.7776e+02],\n",
              "        [-4.1270e+00],\n",
              "        [ 2.0154e+02],\n",
              "        [ 5.7269e+03],\n",
              "        [ 2.2047e+03],\n",
              "        [ 8.1648e+01],\n",
              "        [ 4.2944e+00],\n",
              "        [-6.5415e+00],\n",
              "        [ 5.1655e-01],\n",
              "        [-5.7766e+00],\n",
              "        [ 5.7695e+03],\n",
              "        [ 3.8361e+02],\n",
              "        [ 6.8106e-01],\n",
              "        [ 5.4025e+00],\n",
              "        [ 1.9399e+01],\n",
              "        [ 1.0132e+02],\n",
              "        [ 3.4000e+01],\n",
              "        [ 1.3755e+03]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_batch, target_batch = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "lGF21kCHLvI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_batch.flatten(1,-1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yow7JzKLmw7",
        "outputId": "0cda64b4-593e-4fc7-d388-bb5d3732f814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1387])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1TL8aR6L2N1",
        "outputId": "dd01de24-7848-4089-bdda-019db6f30b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ukj1K-rLYms",
        "outputId": "1f922980-a19d-4b10-ca87-8155ebf5d427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (layers): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=1387, out_features=512, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (6): ReLU()\n",
              "    (7): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SQR3181F6R9",
        "outputId": "a672ff57-d7ce-47d0-9449-8d34eb3775b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan],\n",
              "        [nan]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skorch"
      ],
      "metadata": {
        "id": "N-lvYVU6F6Zh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ee79e6-4619-42d3-97f7-17b37f94d82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting skorch\n",
            "  Downloading skorch-0.13.0-py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.8.10)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.65.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (3.1.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import skorch"
      ],
      "metadata": {
        "id": "oXhU2loImLkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "WGwXU2IHorIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning batch sie, epochs, optimizer, lr"
      ],
      "metadata": {
        "id": "evMvnGq-os2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = skorch.NeuralNetRegressor(\n",
        "    module=mlp\n",
        "    # max_epochs=150,\n",
        "    # batch_size=10\n",
        ")"
      ],
      "metadata": {
        "id": "w57uV7zLF6en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'optimizer': [optim.RMSprop, optim.Adagrad, optim.Adadelta,\n",
        "                  optim.Adam, optim.Adamax, optim.NAdam],\n",
        "     'batch_size': [32, 64, 128],\n",
        "    'optimizer__lr': [0.0001, 0.0005, 0.001, 0.002, 0.003],\n",
        "    'optimizer__momentum': [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],\n",
        "    'max_epochs': [50,80,100]\n",
        "}\n"
      ],
      "metadata": {
        "id": "66AV5-zJF6hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)"
      ],
      "metadata": {
        "id": "VZQlUNnqpi_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making X and y labels"
      ],
      "metadata": {
        "id": "4ZJnQefGptEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the individual tensors\n",
        "record_tensors_ip = []\n",
        "record_tensors_op=[]\n",
        "\n",
        "# Iterate over the data loader and collect the tensors\n",
        "for ip, op in train_set:\n",
        "    record_tensors_ip.append(ip)\n",
        "    record_tensors_op.append(op)"
      ],
      "metadata": {
        "id": "R5hht7gVr1ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.stack(record_tensors_ip)\n",
        "y= torch.stack(record_tensors_op)"
      ],
      "metadata": {
        "id": "nNQYhKj10qXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2zq63AFqvP5",
        "outputId": "728dd11b-e4b7-4bd8-9835-a3883f9f8ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16430, 1387])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=y.reshape(-1,1)"
      ],
      "metadata": {
        "id": "OlibJaLY1WFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXQ4mcua_cyw",
        "outputId": "c6b17f54-9038-44fd-b2f5-150c0d632659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16430, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting the model"
      ],
      "metadata": {
        "id": "_FpUuAIp1fCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = skorch.NeuralNetRegressor(\n",
        "    module=mlp,\n",
        "    optimizer= optim.Adam,\n",
        "    criterion=nn.MSELoss(),\n",
        "    # max_epochs=50,\n",
        "    batch_size=10,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# model = NeuralNetClassifier(\n",
        "#     PimaClassifier,\n",
        "#     criterion=nn.BCELoss,\n",
        "#     optimizer=optim.Adamax,\n",
        "#     max_epochs=100,\n",
        "#     batch_size=10,\n",
        "#     verbose=False\n",
        "# )"
      ],
      "metadata": {
        "id": "78jpkBeP1yP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    # 'optimizer': [optim.RMSprop, optim.Adagrad, optim.Adadelta,\n",
        "    #               optim.Adam, optim.Adamax, optim.NAdam],\n",
        "    # 'batch_size': [32, 64, 128],\n",
        "    # 'optimizer__lr': [0.0001, 0.0005, 0.001, 0.002, 0.003],\n",
        "    # 'optimizer__momentum': [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],\n",
        "    'max_epochs': [50,80,100]\n",
        "}"
      ],
      "metadata": {
        "id": "Z0jbn5101yP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=2)"
      ],
      "metadata": {
        "id": "L2aYb95X1yQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result = grid.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "OSB4QbcI1oGk",
        "outputId": "405d395d-b8fc-4dfb-923a-c006e55e107e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-cfb21ddd2071>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    451\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_PEOwsNL13lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hyperparameter Tuning\n",
        "\n",
        "###Initializing the number of layers"
      ],
      "metadata": {
        "id": "4ixGgRtWdAuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##layers=3"
      ],
      "metadata": {
        "id": "s6W23h3vdbJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=512\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "zwWHfOyqdJh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "hsAPkJCOdJh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7732fe57-d975-45b0-a85c-940779c50d4e",
        "id": "MQcj3UA3dJh_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 13.37\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 5.06\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 5.22\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 5.41\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 4.87\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 5.99\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 4.77\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 4.77\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 5.97\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 4.78\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 5.04\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 5.69\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 4.77\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 5.30\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 5.32\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 4.75\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 5.74\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 5.32\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 4.77\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 6.37\n",
            "Training process has finished. Time taken is 113.29233431816101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080f1546-d902-494c-a775-0e2da8f24a15",
        "id": "IHY0yptZdJiA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 46039.599349818585\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 82865.26028978653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z5QpWLofeiSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sutK7Z6genPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##layers=4"
      ],
      "metadata": {
        "id": "6ewqQ1Q7enn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=512\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "ycJQ_2-henn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "O_cooQkxenn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c281fac3-4ab3-4694-cce4-6b700b4cd9b8",
        "id": "JJ5y41gyenqH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 5.57\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 4.70\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 4.52\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 6.16\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 4.91\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 4.86\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 6.05\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 4.81\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 5.21\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 5.67\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 4.83\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 5.80\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 6.26\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 5.04\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 6.02\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 5.24\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 5.48\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 5.42\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 4.85\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 5.95\n",
            "Training process has finished. Time taken is 107.36275148391724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77faa5b3-4b83-495c-d10f-a217c65ad514",
        "id": "jMXvQoV_enqL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 32693.866327709165\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 72993.5774151891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qWWyfF3senqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##layers=5"
      ],
      "metadata": {
        "id": "Jefd2jhkfWYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=512\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "Q87v1y-FfWYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "4InbneTOfWYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f3f14aa-e09c-4781-a34d-dfb3cc34d597",
        "id": "CfkNavC1fWYm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 6.69\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 7.45\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 6.28\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 7.24\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 6.50\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 7.05\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 6.80\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 6.79\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 7.00\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 6.47\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 7.25\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 6.29\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 7.51\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 6.29\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 7.48\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 6.32\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 7.49\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 6.32\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 7.48\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 6.29\n",
            "Training process has finished. Time taken is 136.9930238723755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "218e8a7e-05cc-4a39-c99f-9a7abff6eb68",
        "id": "qpsvbwpQfWYr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 8933.646734787882\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 54878.90346602896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3AKmaG9GfWYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##layers=6"
      ],
      "metadata": {
        "id": "M2BGvMEpg7Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=512\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "A0-tsZG5g7Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "fplnexnEg7Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f6d69f-6e89-4e15-ebba-a28c377a4b9f",
        "id": "kjrWUEhCg7Fo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 11.94\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 6.43\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 7.94\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 7.87\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 8.82\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 9.00\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 7.81\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 8.94\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 7.92\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 9.05\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 8.67\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 8.28\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 9.12\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 7.89\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 9.10\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 8.60\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 9.57\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 9.16\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 8.03\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 9.07\n",
            "Training process has finished. Time taken is 173.22720766067505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca8a8db-1d72-4836-88f7-dbac94465271",
        "id": "mNB4XMY1g7Fr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 35689.51569290848\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 77122.47669966245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cx_63L-BhqSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proceeding with 5 layers. tuning the neurons"
      ],
      "metadata": {
        "id": "tWHFcM3Ckq56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##neurons=1024"
      ],
      "metadata": {
        "id": "352lWQ_akyne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=1024\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "_X_M6iIlkynz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "BDJcl3OBkyn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871dadd5-55b2-4532-b724-c2ccf101e163",
        "id": "c-SZDXl5kyn-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 18.51\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 16.71\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 17.87\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 22.06\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 28.88\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 22.17\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 32.36\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 23.20\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 20.93\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 21.71\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 21.26\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 21.63\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 21.35\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 20.99\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 21.96\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 20.76\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 22.39\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 22.43\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 22.01\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 21.04\n",
            "Training process has finished. Time taken is 440.2369203567505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2355adb6-3205-4bc2-fd7a-bcf72c3e4162",
        "id": "M-sbSv3QkyoF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 46151.40270158622\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 85679.74331944234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jUqNU0Psk5DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##neurons=768"
      ],
      "metadata": {
        "id": "C357FokrlQed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=768\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "wB6eruuklQer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "uP_baig1lQey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb7df20d-4140-40a0-936e-9b109f1c00bc",
        "id": "XV-P2_gUlQe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 9.33\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 10.49\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 11.08\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 12.89\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 11.78\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 12.29\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 12.54\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 12.51\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 12.67\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 13.04\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 13.43\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 12.26\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 12.02\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 12.62\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 12.63\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 12.62\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 12.64\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 12.64\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 12.46\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 12.00\n",
            "Training process has finished. Time taken is 243.95908665657043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIkEk5L3lQe8",
        "outputId": "1803fb86-cbc2-4e01-dfb5-4fee4c1e07e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 42457.44449924301\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 78065.58092123545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gJaR_upllbZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##neurons=512"
      ],
      "metadata": {
        "id": "mXsYSVL2lbtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=512\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "Q87GhSnKlbt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "oVtTpS4ulbt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b032a8-c585-4463-c13d-e44c7b8683eb",
        "id": "WRs4ndqxlbt8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 8.19\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 6.34\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 8.48\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 11.43\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 8.22\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 8.62\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 7.24\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 9.75\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 9.11\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 9.50\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 7.49\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 6.14\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 7.23\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 6.27\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 6.90\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 6.64\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 6.59\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 7.62\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 6.50\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 7.13\n",
            "Training process has finished. Time taken is 155.4104347229004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu4J_xhylbuA",
        "outputId": "f6b53951-1ad1-4104-8fc1-e4335d71d85f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 34139.81565825409\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 72279.50304992679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JNCaWtjmnrzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##neurons=256"
      ],
      "metadata": {
        "id": "GDt1T2U0nvOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(hidden_layer, hidden_layer, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "6rw7haOjnvOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "dZeQhqmSnvOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cfdfcf6-59da-44ef-f8c9-5c7439f5dde3",
        "id": "KzW87E3XnvOS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 2.65\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 3.01\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 3.37\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 2.76\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 2.75\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 2.72\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 3.26\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 3.31\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 2.64\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 2.65\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 2.67\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 3.39\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 3.26\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 2.69\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 2.69\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 2.70\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 3.46\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 3.12\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 2.71\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 2.74\n",
            "Training process has finished. Time taken is 58.544837474823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL7YL9iVnvOU",
        "outputId": "5d3db7b4-c286-41a4-9047-479978e8766d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 35062.252907045535\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 74871.90164827972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic"
      ],
      "metadata": {
        "id": "O-wWhjn2CJdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 786, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(786, 512, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "emSOB2-BCNcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "p2y_DWdhCNc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd6104d-c06e-417b-9965-49267c5d1d5f",
        "id": "FjsTzo53CNc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 5.71\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 5.47\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 5.19\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 6.57\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 5.54\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 6.43\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 5.61\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 6.67\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 6.06\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 5.55\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 6.36\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 5.46\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 6.53\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 5.44\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 6.30\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 5.67\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 5.65\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 6.78\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 5.55\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 6.63\n",
            "Training process has finished. Time taken is 119.17970156669617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e23cfc8-963e-4137-e2e4-c49ec8bb6791",
        "id": "ZYUca8jFCNc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 26870.874534507133\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 65020.630912577784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x6tIKv07CX3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dyanmic 2"
      ],
      "metadata": {
        "id": "3RA8tLQWFmKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 512, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(256, 128, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "ZeioSV8yFnkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "dQaCBRxlFnkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "385f5286-a6f2-4879-8a83-ca8a3b371ea2",
        "id": "n2zea7yVFnkB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 5.42\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 3.54\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 3.09\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 4.23\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 3.56\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 3.63\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 3.69\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 3.85\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 3.15\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 3.13\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 3.57\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 3.89\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 3.09\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 3.14\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 3.48\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 3.92\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 3.11\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 3.09\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 3.38\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 3.98\n",
            "Training process has finished. Time taken is 71.92707180976868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed51644-167d-457b-d99d-472c35a12b49",
        "id": "4wqHSSIhFnkC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 33544.97108113878\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 70359.13318612229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZU0gylKFvX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SRAU8zEJJ_Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer tuning"
      ],
      "metadata": {
        "id": "kQVO-Ev_KCJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adam"
      ],
      "metadata": {
        "id": "UNB0ROPTJ_SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 786, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(786, 512, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "uh4oj-eAJ_SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "HoUnc7JFJ_SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e037cf-c71b-4e54-ea7e-a6e38e49aaac",
        "id": "luSXQYdOJ_SL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 8.60\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 7.77\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 9.97\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 10.25\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 10.08\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 7.89\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 6.56\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 5.73\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 6.07\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 6.31\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 5.82\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 6.85\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 5.71\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 6.75\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 6.07\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 6.93\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 5.71\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 7.16\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 5.67\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 6.89\n",
            "Training process has finished. Time taken is 142.80548453330994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb761498-2d06-4f13-da47-2ad7da02c8d5",
        "id": "-G1t0r-iJ_SL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 24739.305803708332\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 63581.41863553035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3bzrd9usJ_SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adamax"
      ],
      "metadata": {
        "id": "YXQD2Y4jKSXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 786, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(786, 512, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "6OH20DtQKTe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adamax(mlp.parameters(), lr=0.0005, betas=(0.9,0.95))\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "k798ITgUKTfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0606b3-2468-47bd-8400-c3d66021bfe6",
        "id": "y80e0l6vKTfA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 9.50\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 6.54\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 6.35\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 7.27\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 6.43\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 6.74\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 6.56\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 6.45\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 6.70\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 6.36\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 6.86\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 6.42\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 7.23\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 6.63\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 7.79\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 6.45\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 6.86\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 6.31\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 7.02\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 6.14\n",
            "Training process has finished. Time taken is 136.6136462688446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LwU7tnlKTfB",
        "outputId": "1894266c-dd64-4800-f9f2-18f08e71d697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 31584.791863592964\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 71754.17680321276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LaXHEoArKZM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSProp"
      ],
      "metadata": {
        "id": "aat4Fhv7KZf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 786, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(786, 512, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "cc8ja7wQKZf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.RMSprop(mlp.parameters(), lr=0.0005, momentum=0.8)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "0ph6iNdJKZf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9bb263-6a56-4975-ea81-74b9bf8a875b",
        "id": "1G7xolr8KZf_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 6.95\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 6.87\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 6.79\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 7.44\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 6.40\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 7.43\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 6.62\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 7.66\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 7.07\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 7.39\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 8.04\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 7.11\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 7.79\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 6.93\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 8.44\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 7.06\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 7.98\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 7.47\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 8.18\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 8.05\n",
            "Training process has finished. Time taken is 147.66697216033936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AtRw6T0KZgB",
        "outputId": "4c6db370-bdfd-4507-a482-1608a6cf3945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 27448.095478300955\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 74746.31529967973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ackEBjESKh5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adagrad"
      ],
      "metadata": {
        "id": "EmqLnt92Kxk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 786, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(786, 512, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "wizswN6yKxk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adagrad(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "E9s-IZ3MKxk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03d6627-6031-4a77-95d5-d7481d483c2b",
        "id": "QPrGq3pfKxk6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 6.53\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 7.09\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 4.41\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 5.02\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 4.19\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 3.92\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 4.78\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 4.45\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 3.84\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 4.46\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 4.67\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 3.97\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 4.27\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 4.94\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 4.12\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 4.58\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 5.64\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 4.05\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 4.16\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 5.00\n",
            "Training process has finished. Time taken is 94.11319541931152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zftL3Z_NKxk7",
        "outputId": "5ca950f0-d1fa-4867-d035-0e2a26df8d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 338017.01225521305\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 349593.2104329467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MyqKUkP5PYqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NAdam"
      ],
      "metadata": {
        "id": "g-WcbUtEU5dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 786, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(786, 512, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "qfu6NTOsU5dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.NAdam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "5PzksfYsU5da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5cab1df-b9d8-417b-906f-fdab310b8c57",
        "id": "57J_NZHaU5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 9.91\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 7.27\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 6.83\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 5.92\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 6.82\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 5.90\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 6.40\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 6.16\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 6.05\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 6.64\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 5.94\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 7.22\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 5.95\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 6.82\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 5.86\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 6.84\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 5.86\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 6.80\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 6.23\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 6.68\n",
            "Training process has finished. Time taken is 132.10044384002686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94be47b4-42ff-4cb2-c17d-873783351635",
        "id": "EadhRJlhU5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 38652.47938300552\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 74078.1636606325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nl3FsOTGU9iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate tuning"
      ],
      "metadata": {
        "id": "467e5g8ZjtKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LR=0.0001"
      ],
      "metadata": {
        "id": "9vZ9WmSJjsCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 786, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(786, 512, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "QWH4IqBUjsCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "XGG66lgRjsCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48aeb6f-3ebf-4284-9684-22bc474da874",
        "id": "aHHeyt7pjsCp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 8.49\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 7.46\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 12.22\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 12.61\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 11.70\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 9.45\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 8.63\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 9.56\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 7.33\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 9.54\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 8.00\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 6.14\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 5.52\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 6.42\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 5.60\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 7.59\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 9.92\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 8.79\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 9.32\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 8.80\n",
            "Training process has finished. Time taken is 173.13592338562012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d26a11e-b5db-4616-fd7b-06a0f31b7517",
        "id": "9hXpr0QyjsCq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 66768.10215552914\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 100484.27418224295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HCdk9457j2IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LR = 0.0005"
      ],
      "metadata": {
        "id": "BJVhrr1zj26d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "pFNiynOgj6ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # for input_batch, target_batch in train_loader:\n",
        "    #   predict_batch = mlp(input_batch)\n",
        "    #   mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "    #   train_mse.append(mse)\n",
        "\n",
        "    # if (epoch+1)%5==0:\n",
        "    #     print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d612578-d4f8-41ab-86c0-52967a18e0f1",
        "id": "S-byJw53j6co"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 6.08\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 5.07\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 5.51\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 5.89\n",
            "Starting epoch 5\n",
            "time taken for epoch 5 is 5.35\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 6.42\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 5.75\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 6.57\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 5.36\n",
            "Starting epoch 10\n",
            "time taken for epoch 10 is 6.04\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 5.78\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 5.39\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 6.39\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 5.35\n",
            "Starting epoch 15\n",
            "time taken for epoch 15 is 6.39\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 5.36\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 6.22\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 6.14\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 5.35\n",
            "Starting epoch 20\n",
            "time taken for epoch 20 is 6.47\n",
            "Training process has finished. Time taken is 116.87729406356812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tSwafRej6cp",
        "outputId": "1da3844e-3f2f-4211-e56f-b60b323b10ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 25870.7025299591\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 65166.477607904024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HwrlsFVLj80P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LR = 0.001"
      ],
      "metadata": {
        "id": "0bzOgX9YkBI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "QgTa8yNXkBJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_d8gxgjkBJG",
        "outputId": "ae4983d4-fc7c-4804-bef6-51f423bd1954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 7.84\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 6.57\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 7.79\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 7.50\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 191785.71222056026\n",
            "time taken for epoch 5 is 8.32\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 9.18\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 7.52\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 8.26\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 7.30\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 163596.0986053243\n",
            "time taken for epoch 10 is 8.77\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 8.96\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 7.39\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 8.78\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 7.55\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 125911.82953118725\n",
            "time taken for epoch 15 is 8.33\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 8.10\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 7.61\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 8.44\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 7.26\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 102287.45024273077\n",
            "time taken for epoch 20 is 8.55\n",
            "Training process has finished. Time taken is 160.0033242702484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-hgEvBBkBJH",
        "outputId": "7fe8910c-aefa-461b-90f7-d1cac6f18a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 28511.12896683742\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 68895.09800974824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6kOqg7EqkKhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LR = 0.005"
      ],
      "metadata": {
        "id": "fCcK-egbkWau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "A--u7uJNkWa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLHsuzT5kWa2",
        "outputId": "9cd96982-ad8d-4aeb-bc9c-f62974a0eca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 7.83\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 6.64\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 8.02\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 8.50\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 136173.21998140207\n",
            "time taken for epoch 5 is 8.81\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 10.72\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 8.34\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 8.92\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 9.41\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 109916.78320603375\n",
            "time taken for epoch 10 is 8.19\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 8.97\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 9.39\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 8.53\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 9.27\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 94363.22653811541\n",
            "time taken for epoch 15 is 9.35\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 8.32\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 9.18\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 9.70\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 8.34\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 80926.70905999199\n",
            "time taken for epoch 20 is 9.81\n",
            "Training process has finished. Time taken is 176.23645663261414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO3VHPfgkWa3",
        "outputId": "50dfdf17-aa55-4bc5-a2ae-8a183175c232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 32829.117221064356\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 71275.00195161779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_VPtR15TkZne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LR = 0.01"
      ],
      "metadata": {
        "id": "XFv-qV1gkbP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "ezhaYxWakbP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX1Mm1NYkbP_",
        "outputId": "a172214e-f8cb-4971-b47b-a80ea8eb9c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 8.21\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 6.89\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 8.16\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 8.72\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 123082.86404113447\n",
            "time taken for epoch 5 is 9.30\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 9.21\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 8.19\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 9.53\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 9.95\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 119040.74967316948\n",
            "time taken for epoch 10 is 8.93\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 9.56\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 9.73\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 9.46\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 9.57\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 96192.92493235446\n",
            "time taken for epoch 15 is 9.82\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 9.87\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 8.85\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 9.67\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 9.68\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 80097.04285983791\n",
            "time taken for epoch 20 is 9.50\n",
            "Training process has finished. Time taken is 182.80475115776062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd5WMOENkbP_",
        "outputId": "bdd5f59b-bdef-42a3-b3f4-8f24d42e7b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 24289.72069592719\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 69893.86088223776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4w6fB4OFkeFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LR = 0.02"
      ],
      "metadata": {
        "id": "vk0v9cxXkebU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.02)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "GcT3up7Lkebc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsyaXh3_kebd",
        "outputId": "e2094320-be9f-4844-8f06-58054196b670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 6.97\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 7.80\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 7.15\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 9.77\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 279861.3557956153\n",
            "time taken for epoch 5 is 9.39\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 8.43\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 9.66\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 9.66\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 9.60\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 180470.4783257699\n",
            "time taken for epoch 10 is 10.65\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 9.84\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 9.37\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 9.71\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 9.86\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 142125.53459391053\n",
            "time taken for epoch 15 is 9.72\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 9.32\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 9.41\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 9.61\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 9.84\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 120851.0222555723\n",
            "time taken for epoch 20 is 10.13\n",
            "Training process has finished. Time taken is 185.8779900074005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eemdZBcrkebe",
        "outputId": "d5781e51-f99b-422d-b269-7dd4ca665e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 51018.58743673057\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 99137.40790643258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "grwPZTaDkhWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Learning Rate Schedulers"
      ],
      "metadata": {
        "id": "ltnWruew13L-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Constant LR"
      ],
      "metadata": {
        "id": "kPi6Z0Zt3Z4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "gWvBwgS13VK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d7078f-e2c9-42d1-d5a7-8419ae55771c",
        "id": "0OnxDY023VLB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 12.81\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 12.80\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 9.59\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 9.12\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 241132.9766242507\n",
            "time taken for epoch 5 is 9.19\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 8.07\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 9.15\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 9.20\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 8.07\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 171624.97038605914\n",
            "time taken for epoch 10 is 9.12\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 9.43\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 9.41\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 9.22\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 9.03\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 136841.90374155858\n",
            "time taken for epoch 15 is 8.70\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 9.10\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 8.64\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 8.62\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 9.11\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 110548.4053904942\n",
            "time taken for epoch 20 is 8.06\n",
            "Training process has finished. Time taken is 186.46833491325378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3865efcd-a9d1-41c8-f594-1e4bdceac4ac",
        "id": "xYVGHySI3VLC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 24381.705026025742\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 54271.27726536941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJC9lFwY3fUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step LR"
      ],
      "metadata": {
        "id": "-NsVdcf_3pS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.005)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "-8i0NE1p3kOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8bdbbd-ed55-4092-912f-42ddc8c81623",
        "id": "hzZxI1Xr3kOt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 10.82\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 12.03\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 8.61\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 9.98\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 135756.845505824\n",
            "time taken for epoch 5 is 8.41\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 9.44\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 9.77\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 9.62\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 9.82\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 93703.80708934931\n",
            "time taken for epoch 10 is 9.49\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 8.49\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 9.28\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 9.96\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 8.43\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 77949.92909222575\n",
            "time taken for epoch 15 is 9.69\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 9.45\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 8.69\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 9.06\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 9.32\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 69993.00017743009\n",
            "time taken for epoch 20 is 8.69\n",
            "Training process has finished. Time taken is 189.03265714645386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvubKC-m3kOz",
        "outputId": "4f1dc69d-f661-4e48-ba5c-538ca0a796db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 46093.72855681143\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 88565.2647303534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rmll_pK64ZWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MultiStep LR"
      ],
      "metadata": {
        "id": "DFGawUXE4b9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5,9,15], gamma=0.1)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "3oe2H8NV4b9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447499dd-9a57-4190-ada4-83c010599a8a",
        "id": "57skWc6d4b9n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 13.66\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 11.59\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 9.88\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 7.62\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 166703.83402953285\n",
            "time taken for epoch 5 is 9.44\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 8.16\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 7.83\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 8.40\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 7.43\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 122840.78512307408\n",
            "time taken for epoch 10 is 8.80\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 8.15\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 7.80\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 8.55\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 7.28\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 106369.55284651411\n",
            "time taken for epoch 15 is 8.42\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 7.52\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 8.55\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 9.00\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 7.48\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 97987.57375575739\n",
            "time taken for epoch 20 is 8.42\n",
            "Training process has finished. Time taken is 173.98729133605957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xv-F_xc4b9s",
        "outputId": "4b3ab90f-0cc3-4cc2-a717-6558fe4ad35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 72732.95918717608\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 103371.4247014309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vCa7V8u38kVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exponential LR"
      ],
      "metadata": {
        "id": "dHPRDLADAGqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "t4zh4l2_AGq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5a9850-08f2-412f-c3f8-85f4d6fc4783",
        "id": "J8ytJwo3AGq9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 7.69\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 9.43\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 9.59\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 8.67\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 185980.78480656745\n",
            "time taken for epoch 5 is 9.43\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 9.43\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 8.56\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 9.41\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 9.26\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 131504.2790074839\n",
            "time taken for epoch 10 is 8.63\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 9.32\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 9.09\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 10.27\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 9.46\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 102812.3531245507\n",
            "time taken for epoch 15 is 8.35\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 9.34\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 9.51\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 8.33\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 9.32\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 85507.1857350324\n",
            "time taken for epoch 20 is 9.44\n",
            "Training process has finished. Time taken is 182.55334568023682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be05876-f37d-4fe2-d8a1-6f9cd7097571",
        "id": "mEGdWq7OAGq-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 29471.77895711571\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 55866.94666517259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "75AyK4P0BD1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Will be using both, constant LR and Exponential LR going forward"
      ],
      "metadata": {
        "id": "1rFkCg00Vc-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning Activation function"
      ],
      "metadata": {
        "id": "jC1vi15kVjvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear activation"
      ],
      "metadata": {
        "id": "N-h0PxRsZ-Ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 786, bias=True),\n",
        "        # nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(786, 512, bias=True),\n",
        "        # nn.ReLU(),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        # nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        # nn.ReLU(),\n",
        "        nn.Linear(256, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "iKE1Boh0XEsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "D93xs5a5WWvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9072e63-a57a-4fab-a4fe-8495585b0152",
        "id": "0YSYwEE8WWv9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 13.08\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 12.52\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 12.13\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 7.95\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 334478.6421390702\n",
            "time taken for epoch 5 is 7.88\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 8.52\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 7.48\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 8.59\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 7.54\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 224872.55404383468\n",
            "time taken for epoch 10 is 8.49\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 8.52\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 7.50\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 8.41\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 7.38\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 181753.45210046013\n",
            "time taken for epoch 15 is 9.79\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 7.46\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 8.48\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 8.02\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 7.97\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 158942.3907679989\n",
            "time taken for epoch 20 is 8.53\n",
            "Training process has finished. Time taken is 176.2247724533081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a46c612-6a29-4cce-f83d-61c3a786e4d1",
        "id": "QifNLvZpWWwB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 89642.38121686914\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 84298.48815632299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WxN0ltx4X2w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RELU"
      ],
      "metadata": {
        "id": "0QqrkZvjabok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 786, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(786, 512, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "pp4d8JJSaboq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "nJnN9pj2abor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e15fb56c-bd3a-439b-9ac4-a122ca2080ce",
        "id": "Kr5I_LBGabos"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 14.47\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 11.74\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 12.15\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 17.60\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 167395.20336910346\n",
            "time taken for epoch 5 is 13.39\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 15.95\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 16.75\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 17.01\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 15.01\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 122161.97134817169\n",
            "time taken for epoch 10 is 14.54\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 15.39\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 14.94\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 13.98\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 13.69\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 98518.00080788086\n",
            "time taken for epoch 15 is 13.83\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 9.88\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 8.72\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 9.92\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 10.04\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 82215.17601118996\n",
            "time taken for epoch 20 is 9.37\n",
            "Training process has finished. Time taken is 268.4218466281891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "353fb043-c604-40e6-e53c-9e0d144c06c4",
        "id": "DT7_1ZF6abou"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 30233.621827098952\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 57676.51164967386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9uwyvuyagpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leaky Relu"
      ],
      "metadata": {
        "id": "uGjCyuDZahsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 786, bias=True),\n",
        "        nn.LeakyReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(786, 512, bias=True),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        nn.LeakyReLU(),\n",
        "        # nn.Dropout(p=0.33),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(256, output_layer),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "O91cz9mEahsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "8ZGdlIwBahsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c17e9ce-6e59-43d6-82a2-d503a1ae867f",
        "id": "G4_H2Vb8ahsb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 8.82\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 7.73\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 8.79\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 8.62\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 166473.43368354926\n",
            "time taken for epoch 5 is 7.94\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 12.21\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 13.17\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 13.12\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 12.88\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 119369.33508327896\n",
            "time taken for epoch 10 is 9.16\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 8.57\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 8.70\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 7.70\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 8.68\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 95610.57675859302\n",
            "time taken for epoch 15 is 7.68\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 9.83\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 9.44\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 7.84\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 8.78\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 79682.51680413494\n",
            "time taken for epoch 20 is 8.27\n",
            "Training process has finished. Time taken is 187.94348573684692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a194aae-bcc5-4c84-f505-38cab4d982cd",
        "id": "uYxEEkxkahsc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 27998.07028576843\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 60170.18266456874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_OZRARWaa5Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TanH\n"
      ],
      "metadata": {
        "id": "egdFz5O9a5qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # self.layers = nn.Sequential(\n",
        "    #     nn.Flatten(),\n",
        "    #     nn.Linear(input_layer, 786, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     # nn.Dropout(p=0.33),\n",
        "    #     nn.Linear(786, 512, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     nn.Linear(512, 384, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     # nn.Dropout(p=0.33),\n",
        "    #     nn.Linear(384, 256, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     nn.Linear(256, output_layer),\n",
        "    # )\n",
        "\n",
        "    self.fc1 = nn.Linear(input_layer, 786, bias=True)\n",
        "    self.fc2 = nn.Linear(786, 512, bias=True)\n",
        "    self.fc3 = nn.Linear(512, 384, bias=True)\n",
        "    self.fc4 = nn.Linear(384, 256, bias=True)\n",
        "    self.fc5 = nn.Linear(256, output_layer)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = torch.tanh(self.fc1(x))\n",
        "    x = torch.tanh(self.fc2(x))\n",
        "    x = torch.tanh(self.fc3(x))\n",
        "    x = torch.tanh(self.fc4(x))\n",
        "    x = self.fc5(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "    # x= torch.tanh(x)\n",
        "    # return self.layers(x)"
      ],
      "metadata": {
        "id": "j0T3CGtKa5qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "vc_TDrOCa5qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaeaa7bb-6cf8-45af-f5ab-e60bca15d3eb",
        "id": "am1Yv4c_a5qc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 12.29\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 13.12\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 14.16\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 17.62\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 5924446.890717637\n",
            "time taken for epoch 5 is 13.08\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 13.00\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 12.94\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 11.97\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 8.46\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 5800242.967583059\n",
            "time taken for epoch 10 is 8.02\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 10.00\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 8.71\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 8.26\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 8.82\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 5710191.760450141\n",
            "time taken for epoch 15 is 7.66\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 9.99\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 7.95\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 8.49\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 8.73\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 5643521.333159085\n",
            "time taken for epoch 20 is 7.66\n",
            "Training process has finished. Time taken is 210.92923188209534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57872370-b5bb-485b-9f7e-743ed4b3ab73",
        "id": "kvA-Q81Ua5qh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 5423226.631122703\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 5253062.517927454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softplus\n"
      ],
      "metadata": {
        "id": "w1BQeN4MbJNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # self.layers = nn.Sequential(\n",
        "    #     nn.Flatten(),\n",
        "    #     nn.Linear(input_layer, 786, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     # nn.Dropout(p=0.33),\n",
        "    #     nn.Linear(786, 512, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     nn.Linear(512, 384, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     # nn.Dropout(p=0.33),\n",
        "    #     nn.Linear(384, 256, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     nn.Linear(256, output_layer),\n",
        "    # )\n",
        "\n",
        "    self.fc1 = nn.Linear(input_layer, 786, bias=True)\n",
        "    self.fc2 = nn.Linear(786, 512, bias=True)\n",
        "    self.fc3 = nn.Linear(512, 384, bias=True)\n",
        "    self.fc4 = nn.Linear(384, 256, bias=True)\n",
        "    self.fc5 = nn.Linear(256, output_layer)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.softplus(self.fc1(x))\n",
        "    x = F.softplus(self.fc2(x))\n",
        "    x = F.softplus(self.fc3(x))\n",
        "    x = F.softplus(self.fc4(x))\n",
        "    x = self.fc5(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "    # x= torch.tanh(x)\n",
        "    # return self.layers(x)"
      ],
      "metadata": {
        "id": "BAsQcSisbJNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "o2AAIQ9ebJNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ecd02a-f839-446c-dd74-bb2fbfab73e4",
        "id": "oKmpFCd1bJNv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 15.29\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 15.05\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 16.40\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 12.87\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 238036.6348932362\n",
            "time taken for epoch 5 is 12.83\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 12.69\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 12.98\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 14.02\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 13.16\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 167742.53330995003\n",
            "time taken for epoch 10 is 13.21\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 13.23\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 13.24\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 13.29\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 13.34\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 134887.6894597569\n",
            "time taken for epoch 15 is 13.34\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 13.36\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 13.34\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 13.40\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 13.45\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 116099.48114325503\n",
            "time taken for epoch 20 is 13.47\n",
            "Training process has finished. Time taken is 271.96529960632324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba9babf-4fa6-41e2-f311-aed4dcf21953",
        "id": "gANLwYp_bJNw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 63493.21379632639\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 83224.62644703334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1zKDv7JYgmEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularization"
      ],
      "metadata": {
        "id": "6DZZgeKAmMwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L1\n"
      ],
      "metadata": {
        "id": "DMGcRQSvmAbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # self.layers = nn.Sequential(\n",
        "    #     nn.Flatten(),\n",
        "    #     nn.Linear(input_layer, 786, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     # nn.Dropout(p=0.33),\n",
        "    #     nn.Linear(786, 512, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     nn.Linear(512, 384, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     # nn.Dropout(p=0.33),\n",
        "    #     nn.Linear(384, 256, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     nn.Linear(256, output_layer),\n",
        "    # )\n",
        "\n",
        "    self.fc1 = nn.Linear(input_layer, 786, bias=True)\n",
        "    self.fc2 = nn.Linear(786, 512, bias=True)\n",
        "    self.fc3 = nn.Linear(512, 384, bias=True)\n",
        "    self.fc4 = nn.Linear(384, 256, bias=True)\n",
        "    self.fc5 = nn.Linear(256, output_layer)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.softplus(self.fc1(x))\n",
        "    x = F.softplus(self.fc2(x))\n",
        "    x = F.softplus(self.fc3(x))\n",
        "    x = F.softplus(self.fc4(x))\n",
        "    x = self.fc5(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "    # x= torch.tanh(x)\n",
        "    # return self.layers(x)"
      ],
      "metadata": {
        "id": "Y8MkdMwqmAba"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "l1_lambda = 0.01"
      ],
      "metadata": {
        "id": "h4NJlRi1mAbc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # Compute L1 regularization loss\n",
        "      l1_loss = torch.tensor(0.)\n",
        "      for param in mlp.parameters():\n",
        "          l1_loss += torch.norm(param, p=1)\n",
        "\n",
        "      # Add L1 regularization term to the loss\n",
        "      loss += l1_lambda * l1_loss\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "a0c170b8-76cc-4e7a-9b90-1d8219cdde86",
        "id": "Ls4JThArmAbc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b69cc040f26f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Iterate over the DataLoader for training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0;31m# Get inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "b3c997cf-647a-40e3-da83-7c6d49d64d82",
        "id": "82DrsowjmAbd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-fa91c1c81868>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mpredict_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cO5xLw6omJ7K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNSNDNU2mAbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L2\n"
      ],
      "metadata": {
        "id": "dBlmk-zKpcfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # self.layers = nn.Sequential(\n",
        "    #     nn.Flatten(),\n",
        "    #     nn.Linear(input_layer, 786, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     # nn.Dropout(p=0.33),\n",
        "    #     nn.Linear(786, 512, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     nn.Linear(512, 384, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     # nn.Dropout(p=0.33),\n",
        "    #     nn.Linear(384, 256, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     nn.Linear(256, output_layer),\n",
        "    # )\n",
        "\n",
        "    self.fc1 = nn.Linear(input_layer, 786, bias=True)\n",
        "    self.fc2 = nn.Linear(786, 512, bias=True)\n",
        "    self.fc3 = nn.Linear(512, 384, bias=True)\n",
        "    self.fc4 = nn.Linear(384, 256, bias=True)\n",
        "    self.fc5 = nn.Linear(256, output_layer)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.softplus(self.fc1(x))\n",
        "    x = F.softplus(self.fc2(x))\n",
        "    x = F.softplus(self.fc3(x))\n",
        "    x = F.softplus(self.fc4(x))\n",
        "    x = self.fc5(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "    # x= torch.tanh(x)\n",
        "    # return self.layers(x)"
      ],
      "metadata": {
        "id": "f7hmx30ypcfs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005, weight_decay=0.05)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "# scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "l1_lambda = 0.001"
      ],
      "metadata": {
        "id": "P5PK0hrPpcft"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=20\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # # Compute L1 regularization loss\n",
        "      # l1_loss = torch.tensor(0.)\n",
        "      # for param in mlp.parameters():\n",
        "      #     l1_loss += torch.norm(param, p=1)\n",
        "\n",
        "      # # Add L1 regularization term to the loss\n",
        "      # loss += l1_lambda * l1_loss\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9454f3ae-11b8-4b4b-a20e-0ac2aa7f45cb",
        "id": "E267R9Unpcfu"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 9.65\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 11.15\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 12.46\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 12.61\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 216133.24713383729\n",
            "time taken for epoch 5 is 12.40\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 12.46\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 12.42\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 12.20\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 12.71\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 159728.51190883157\n",
            "time taken for epoch 10 is 13.00\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 13.03\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 12.55\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 12.39\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 14.16\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 130004.26619610334\n",
            "time taken for epoch 15 is 18.24\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 19.30\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 17.11\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 15.11\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 11.92\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 111268.05683094486\n",
            "time taken for epoch 20 is 12.06\n",
            "Training process has finished. Time taken is 266.94141912460327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1859e219-cd56-4d98-d4a8-6399bb2c6cfb",
        "id": "yHsaRch7pcfu"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 49890.407724704775\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 76392.7068461928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nOO6vA0twT7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop-out\n"
      ],
      "metadata": {
        "id": "1DdpKjK7AcIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_layer, 786, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.25),\n",
        "        nn.Linear(786, 512, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.25),\n",
        "        nn.Linear(512, 384, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.25),\n",
        "        nn.Linear(384, 256, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.25),\n",
        "        nn.Linear(256, output_layer),\n",
        "    )\n",
        "\n",
        "  #   self.fc1 = nn.Linear(input_layer, 786, bias=True)\n",
        "  #   self.dropout = nn.Dropout(0.3)\n",
        "  #   self.fc2 = nn.Linear(786, 512, bias=True)\n",
        "  #   self.fc3 = nn.Linear(512, 384, bias=True)\n",
        "  #   self.fc4 = nn.Linear(384, 256, bias=True)\n",
        "  #   self.fc5 = nn.Linear(256, output_layer)\n",
        "\n",
        "\n",
        "  # def forward(self,x):\n",
        "  #   x = F.softplus(self.fc1(x))\n",
        "  #   # x = self.dropout(x)\n",
        "  #   x = F.softplus(self.fc2(x))\n",
        "  #   # x = self.dropout(x)\n",
        "  #   x = F.softplus(self.fc3(x))\n",
        "  #   # x = self.dropout(x)\n",
        "  #   x = F.softplus(self.fc4(x))\n",
        "  #   # x = self.dropout(x)\n",
        "  #   x = self.fc5(x)\n",
        "\n",
        "  #   return x\n",
        "\n",
        "    # x= torch.tanh(x)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n"
      ],
      "metadata": {
        "id": "ugvx_HDrAcIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "l1_lambda = 0.001"
      ],
      "metadata": {
        "id": "FaGr7p3CAcIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=100\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # # Compute L1 regularization loss\n",
        "      # l1_loss = torch.tensor(0.)\n",
        "      # for param in mlp.parameters():\n",
        "      #     l1_loss += torch.norm(param, p=1)\n",
        "\n",
        "      # # Add L1 regularization term to the loss\n",
        "      # loss += l1_lambda * l1_loss\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "146af55c-3b37-468d-e774-b067eccb466e",
        "id": "fMY8TiLdAcIQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 12.69\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 11.90\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 10.19\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 11.77\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 285529.5373291202\n",
            "time taken for epoch 5 is 10.82\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 7.94\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 7.05\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 7.97\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 6.91\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 232906.80386804283\n",
            "time taken for epoch 10 is 8.12\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 7.11\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 8.17\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 7.67\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 7.55\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 204391.6218024524\n",
            "time taken for epoch 15 is 8.17\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 7.18\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 8.59\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 7.09\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 8.02\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 180918.00717631105\n",
            "time taken for epoch 20 is 7.65\n",
            "Starting epoch 21\n",
            "time taken for epoch 21 is 7.60\n",
            "Starting epoch 22\n",
            "time taken for epoch 22 is 8.08\n",
            "Starting epoch 23\n",
            "time taken for epoch 23 is 7.12\n",
            "Starting epoch 24\n",
            "time taken for epoch 24 is 8.07\n",
            "Starting epoch 25\n",
            "train MSE after epoch 25 is 167864.20445966575\n",
            "time taken for epoch 25 is 6.97\n",
            "Starting epoch 26\n",
            "time taken for epoch 26 is 8.03\n",
            "Starting epoch 27\n",
            "time taken for epoch 27 is 6.96\n",
            "Starting epoch 28\n",
            "time taken for epoch 28 is 8.08\n",
            "Starting epoch 29\n",
            "time taken for epoch 29 is 7.52\n",
            "Starting epoch 30\n",
            "train MSE after epoch 30 is 156614.9838673226\n",
            "time taken for epoch 30 is 7.88\n",
            "Starting epoch 31\n",
            "time taken for epoch 31 is 8.44\n",
            "Starting epoch 32\n",
            "time taken for epoch 32 is 7.29\n",
            "Starting epoch 33\n",
            "time taken for epoch 33 is 8.24\n",
            "Starting epoch 34\n",
            "time taken for epoch 34 is 7.31\n",
            "Starting epoch 35\n",
            "train MSE after epoch 35 is 147777.96921184537\n",
            "time taken for epoch 35 is 8.17\n",
            "Starting epoch 36\n",
            "time taken for epoch 36 is 7.51\n",
            "Starting epoch 37\n",
            "time taken for epoch 37 is 7.63\n",
            "Starting epoch 38\n",
            "time taken for epoch 38 is 8.46\n",
            "Starting epoch 39\n",
            "time taken for epoch 39 is 7.38\n",
            "Starting epoch 40\n",
            "train MSE after epoch 40 is 139618.61898578805\n",
            "time taken for epoch 40 is 9.09\n",
            "Starting epoch 41\n",
            "time taken for epoch 41 is 7.12\n",
            "Starting epoch 42\n",
            "time taken for epoch 42 is 8.12\n",
            "Starting epoch 43\n",
            "time taken for epoch 43 is 7.63\n",
            "Starting epoch 44\n",
            "time taken for epoch 44 is 7.84\n",
            "Starting epoch 45\n",
            "train MSE after epoch 45 is 134041.41017699515\n",
            "time taken for epoch 45 is 8.25\n",
            "Starting epoch 46\n",
            "time taken for epoch 46 is 7.18\n",
            "Starting epoch 47\n",
            "time taken for epoch 47 is 8.13\n",
            "Starting epoch 48\n",
            "time taken for epoch 48 is 6.95\n",
            "Starting epoch 49\n",
            "time taken for epoch 49 is 8.01\n",
            "Starting epoch 50\n",
            "train MSE after epoch 50 is 128011.38044625646\n",
            "time taken for epoch 50 is 6.98\n",
            "Starting epoch 51\n",
            "time taken for epoch 51 is 7.97\n",
            "Starting epoch 52\n",
            "time taken for epoch 52 is 7.38\n",
            "Starting epoch 53\n",
            "time taken for epoch 53 is 7.67\n",
            "Starting epoch 54\n",
            "time taken for epoch 54 is 8.18\n",
            "Starting epoch 55\n",
            "train MSE after epoch 55 is 122569.01929779744\n",
            "time taken for epoch 55 is 7.08\n",
            "Starting epoch 56\n",
            "time taken for epoch 56 is 8.28\n",
            "Starting epoch 57\n",
            "time taken for epoch 57 is 7.04\n",
            "Starting epoch 58\n",
            "time taken for epoch 58 is 8.22\n",
            "Starting epoch 59\n",
            "time taken for epoch 59 is 7.01\n",
            "Starting epoch 60\n",
            "train MSE after epoch 60 is 118223.56176277611\n",
            "time taken for epoch 60 is 8.24\n",
            "Starting epoch 61\n",
            "time taken for epoch 61 is 7.68\n",
            "Starting epoch 62\n",
            "time taken for epoch 62 is 7.58\n",
            "Starting epoch 63\n",
            "time taken for epoch 63 is 8.14\n",
            "Starting epoch 64\n",
            "time taken for epoch 64 is 6.99\n",
            "Starting epoch 65\n",
            "train MSE after epoch 65 is 114009.9046206154\n",
            "time taken for epoch 65 is 8.10\n",
            "Starting epoch 66\n",
            "time taken for epoch 66 is 7.01\n",
            "Starting epoch 67\n",
            "time taken for epoch 67 is 8.07\n",
            "Starting epoch 68\n",
            "time taken for epoch 68 is 6.97\n",
            "Starting epoch 69\n",
            "time taken for epoch 69 is 8.07\n",
            "Starting epoch 70\n",
            "train MSE after epoch 70 is 110297.28445553342\n",
            "time taken for epoch 70 is 7.54\n",
            "Starting epoch 71\n",
            "time taken for epoch 71 is 7.62\n",
            "Starting epoch 72\n",
            "time taken for epoch 72 is 8.16\n",
            "Starting epoch 73\n",
            "time taken for epoch 73 is 7.14\n",
            "Starting epoch 74\n",
            "time taken for epoch 74 is 7.94\n",
            "Starting epoch 75\n",
            "train MSE after epoch 75 is 107626.99934567543\n",
            "time taken for epoch 75 is 7.11\n",
            "Starting epoch 76\n",
            "time taken for epoch 76 is 7.87\n",
            "Starting epoch 77\n",
            "time taken for epoch 77 is 6.94\n",
            "Starting epoch 78\n",
            "time taken for epoch 78 is 8.06\n",
            "Starting epoch 79\n",
            "time taken for epoch 79 is 7.52\n",
            "Starting epoch 80\n",
            "train MSE after epoch 80 is 105120.36928730906\n",
            "time taken for epoch 80 is 7.61\n",
            "Starting epoch 81\n",
            "time taken for epoch 81 is 8.32\n",
            "Starting epoch 82\n",
            "time taken for epoch 82 is 8.40\n",
            "Starting epoch 83\n",
            "time taken for epoch 83 is 8.26\n",
            "Starting epoch 84\n",
            "time taken for epoch 84 is 7.32\n",
            "Starting epoch 85\n",
            "train MSE after epoch 85 is 102419.37725982681\n",
            "time taken for epoch 85 is 8.33\n",
            "Starting epoch 86\n",
            "time taken for epoch 86 is 8.43\n",
            "Starting epoch 87\n",
            "time taken for epoch 87 is 7.45\n",
            "Starting epoch 88\n",
            "time taken for epoch 88 is 8.19\n",
            "Starting epoch 89\n",
            "time taken for epoch 89 is 7.42\n",
            "Starting epoch 90\n",
            "train MSE after epoch 90 is 100352.44898547878\n",
            "time taken for epoch 90 is 8.21\n",
            "Starting epoch 91\n",
            "time taken for epoch 91 is 6.92\n",
            "Starting epoch 92\n",
            "time taken for epoch 92 is 7.92\n",
            "Starting epoch 93\n",
            "time taken for epoch 93 is 7.46\n",
            "Starting epoch 94\n",
            "time taken for epoch 94 is 7.54\n",
            "Starting epoch 95\n",
            "train MSE after epoch 95 is 98482.25069761391\n",
            "time taken for epoch 95 is 8.11\n",
            "Starting epoch 96\n",
            "time taken for epoch 96 is 7.10\n",
            "Starting epoch 97\n",
            "time taken for epoch 97 is 8.34\n",
            "Starting epoch 98\n",
            "time taken for epoch 98 is 7.48\n",
            "Starting epoch 99\n",
            "time taken for epoch 99 is 8.32\n",
            "Starting epoch 100\n",
            "train MSE after epoch 100 is 97805.18515172375\n",
            "time taken for epoch 100 is 7.65\n",
            "Training process has finished. Time taken is 790.9921078681946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "c3165eac-0551-4358-ab32-cdfe5fa484c3",
        "id": "swpSpP_bAcIR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fa91c1c81868>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sets the model in evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_mse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mlp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QnVjczpdFNab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## No Drop-out\n"
      ],
      "metadata": {
        "id": "hNtxXbdsxVia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = 1387\n",
        "# hidden_layer=256\n",
        "output_layer=1\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # self.layers = nn.Sequential(\n",
        "    #     nn.Flatten(),\n",
        "    #     nn.Linear(input_layer, 786, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     # nn.Dropout(p=0.33),\n",
        "    #     nn.Linear(786, 512, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     nn.Linear(512, 384, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     # nn.Dropout(p=0.33),\n",
        "    #     nn.Linear(384, 256, bias=True),\n",
        "    #     torch.tanh(),\n",
        "    #     nn.Linear(256, output_layer),\n",
        "    # )\n",
        "\n",
        "    self.fc1 = nn.Linear(input_layer, 786, bias=True)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    self.fc2 = nn.Linear(786, 512, bias=True)\n",
        "    self.fc3 = nn.Linear(512, 384, bias=True)\n",
        "    self.fc4 = nn.Linear(384, 256, bias=True)\n",
        "    self.fc5 = nn.Linear(256, output_layer)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.softplus(self.fc1(x))\n",
        "    # x = self.dropout(x)\n",
        "    x = F.softplus(self.fc2(x))\n",
        "    # x = self.dropout(x)\n",
        "    x = F.softplus(self.fc3(x))\n",
        "    # x = self.dropout(x)\n",
        "    x = F.softplus(self.fc4(x))\n",
        "    # x = self.dropout(x)\n",
        "    x = self.fc5(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "    # x= torch.tanh(x)\n",
        "    # return self.layers(x)"
      ],
      "metadata": {
        "id": "jR1R0lvaxVoB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp=MLP()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.0005)\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "l1_lambda = 0.001"
      ],
      "metadata": {
        "id": "VZa7hnroxVoD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mse=[]\n",
        "train_losses=[]\n",
        "\n",
        "\n",
        "epochs=80\n",
        "\n",
        "total_start_time=time.time()\n",
        "# Run the training loop\n",
        "for epoch in range(epochs): # Testing the epochs between 50 and 100\n",
        "\n",
        "    # Start timing the training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs, targets = data\n",
        "\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      # outputs.to(device)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = criterion(outputs.flatten(), targets)\n",
        "\n",
        "      # # Compute L1 regularization loss\n",
        "      # l1_loss = torch.tensor(0.)\n",
        "      # for param in mlp.parameters():\n",
        "      #     l1_loss += torch.norm(param, p=1)\n",
        "\n",
        "      # # Add L1 regularization term to the loss\n",
        "      # loss += l1_lambda * l1_loss\n",
        "\n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      predict_batch = mlp(input_batch)\n",
        "      mse = mean_squared_error(predict_batch.flatten().tolist(), target_batch.flatten().tolist())\n",
        "      train_mse.append(mse)\n",
        "\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f'train MSE after epoch {epoch+1} is {np.mean(train_mse)}')\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "    print(f'time taken for epoch {epoch+1} is {end_time-start_time:.2f}')\n",
        "\n",
        "# Process is complete.\n",
        "total_end_time=time.time()\n",
        "print(f'Training process has finished. Time taken is {total_end_time-total_start_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baaf2a73-96fc-4367-b912-a83604bf1330",
        "id": "Xe-35nShxVoE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "time taken for epoch 1 is 13.15\n",
            "Starting epoch 2\n",
            "time taken for epoch 2 is 12.49\n",
            "Starting epoch 3\n",
            "time taken for epoch 3 is 9.95\n",
            "Starting epoch 4\n",
            "time taken for epoch 4 is 11.03\n",
            "Starting epoch 5\n",
            "train MSE after epoch 5 is 346859.86231641803\n",
            "time taken for epoch 5 is 12.00\n",
            "Starting epoch 6\n",
            "time taken for epoch 6 is 12.51\n",
            "Starting epoch 7\n",
            "time taken for epoch 7 is 20.87\n",
            "Starting epoch 8\n",
            "time taken for epoch 8 is 18.73\n",
            "Starting epoch 9\n",
            "time taken for epoch 9 is 15.71\n",
            "Starting epoch 10\n",
            "train MSE after epoch 10 is 249567.7824194771\n",
            "time taken for epoch 10 is 12.50\n",
            "Starting epoch 11\n",
            "time taken for epoch 11 is 12.68\n",
            "Starting epoch 12\n",
            "time taken for epoch 12 is 13.57\n",
            "Starting epoch 13\n",
            "time taken for epoch 13 is 13.60\n",
            "Starting epoch 14\n",
            "time taken for epoch 14 is 12.45\n",
            "Starting epoch 15\n",
            "train MSE after epoch 15 is 192286.24783450973\n",
            "time taken for epoch 15 is 9.67\n",
            "Starting epoch 16\n",
            "time taken for epoch 16 is 9.19\n",
            "Starting epoch 17\n",
            "time taken for epoch 17 is 9.51\n",
            "Starting epoch 18\n",
            "time taken for epoch 18 is 9.89\n",
            "Starting epoch 19\n",
            "time taken for epoch 19 is 9.98\n",
            "Starting epoch 20\n",
            "train MSE after epoch 20 is 160611.9260982204\n",
            "time taken for epoch 20 is 10.08\n",
            "Starting epoch 21\n",
            "time taken for epoch 21 is 10.50\n",
            "Starting epoch 22\n",
            "time taken for epoch 22 is 10.66\n",
            "Starting epoch 23\n",
            "time taken for epoch 23 is 10.06\n",
            "Starting epoch 24\n",
            "time taken for epoch 24 is 10.74\n",
            "Starting epoch 25\n",
            "train MSE after epoch 25 is 134974.94837101866\n",
            "time taken for epoch 25 is 11.01\n",
            "Starting epoch 26\n",
            "time taken for epoch 26 is 11.40\n",
            "Starting epoch 27\n",
            "time taken for epoch 27 is 10.67\n",
            "Starting epoch 28\n",
            "time taken for epoch 28 is 10.41\n",
            "Starting epoch 29\n",
            "time taken for epoch 29 is 10.96\n",
            "Starting epoch 30\n",
            "train MSE after epoch 30 is 117568.42424239685\n",
            "time taken for epoch 30 is 11.05\n",
            "Starting epoch 31\n",
            "time taken for epoch 31 is 10.46\n",
            "Starting epoch 32\n",
            "time taken for epoch 32 is 10.85\n",
            "Starting epoch 33\n",
            "time taken for epoch 33 is 10.95\n",
            "Starting epoch 34\n",
            "time taken for epoch 34 is 11.44\n",
            "Starting epoch 35\n",
            "train MSE after epoch 35 is 103833.96475773279\n",
            "time taken for epoch 35 is 10.98\n",
            "Starting epoch 36\n",
            "time taken for epoch 36 is 10.62\n",
            "Starting epoch 37\n",
            "time taken for epoch 37 is 11.45\n",
            "Starting epoch 38\n",
            "time taken for epoch 38 is 11.68\n",
            "Starting epoch 39\n",
            "time taken for epoch 39 is 11.78\n",
            "Starting epoch 40\n",
            "train MSE after epoch 40 is 92470.0079045793\n",
            "time taken for epoch 40 is 11.55\n",
            "Starting epoch 41\n",
            "time taken for epoch 41 is 11.27\n",
            "Starting epoch 42\n",
            "time taken for epoch 42 is 11.81\n",
            "Starting epoch 43\n",
            "time taken for epoch 43 is 11.81\n",
            "Starting epoch 44\n",
            "time taken for epoch 44 is 12.68\n",
            "Starting epoch 45\n",
            "train MSE after epoch 45 is 83609.45130561889\n",
            "time taken for epoch 45 is 12.02\n",
            "Starting epoch 46\n",
            "time taken for epoch 46 is 11.74\n",
            "Starting epoch 47\n",
            "time taken for epoch 47 is 11.68\n",
            "Starting epoch 48\n",
            "time taken for epoch 48 is 12.08\n",
            "Starting epoch 49\n",
            "time taken for epoch 49 is 12.11\n",
            "Starting epoch 50\n",
            "train MSE after epoch 50 is 76454.69965834393\n",
            "time taken for epoch 50 is 12.06\n",
            "Starting epoch 51\n",
            "time taken for epoch 51 is 12.25\n",
            "Starting epoch 52\n",
            "time taken for epoch 52 is 11.83\n",
            "Starting epoch 53\n",
            "time taken for epoch 53 is 11.73\n",
            "Starting epoch 54\n",
            "time taken for epoch 54 is 16.67\n",
            "Starting epoch 55\n",
            "train MSE after epoch 55 is 70644.25451606527\n",
            "time taken for epoch 55 is 25.19\n",
            "Starting epoch 56\n",
            "time taken for epoch 56 is 19.26\n",
            "Starting epoch 57\n",
            "time taken for epoch 57 is 19.72\n",
            "Starting epoch 58\n",
            "time taken for epoch 58 is 19.51\n",
            "Starting epoch 59\n",
            "time taken for epoch 59 is 22.75\n",
            "Starting epoch 60\n",
            "train MSE after epoch 60 is 65807.91687323341\n",
            "time taken for epoch 60 is 16.41\n",
            "Starting epoch 61\n",
            "time taken for epoch 61 is 16.98\n",
            "Starting epoch 62\n",
            "time taken for epoch 62 is 16.59\n",
            "Starting epoch 63\n",
            "time taken for epoch 63 is 14.89\n",
            "Starting epoch 64\n",
            "time taken for epoch 64 is 12.03\n",
            "Starting epoch 65\n",
            "train MSE after epoch 65 is 61389.225173298815\n",
            "time taken for epoch 65 is 12.11\n",
            "Starting epoch 66\n",
            "time taken for epoch 66 is 12.22\n",
            "Starting epoch 67\n",
            "time taken for epoch 67 is 12.21\n",
            "Starting epoch 68\n",
            "time taken for epoch 68 is 11.98\n",
            "Starting epoch 69\n",
            "time taken for epoch 69 is 12.54\n",
            "Starting epoch 70\n",
            "train MSE after epoch 70 is 57458.85773365119\n",
            "time taken for epoch 70 is 13.41\n",
            "Starting epoch 71\n",
            "time taken for epoch 71 is 12.53\n",
            "Starting epoch 72\n",
            "time taken for epoch 72 is 12.73\n",
            "Starting epoch 73\n",
            "time taken for epoch 73 is 12.42\n",
            "Starting epoch 74\n",
            "time taken for epoch 74 is 12.78\n",
            "Starting epoch 75\n",
            "train MSE after epoch 75 is 53886.243673933386\n",
            "time taken for epoch 75 is 12.80\n",
            "Starting epoch 76\n",
            "time taken for epoch 76 is 12.33\n",
            "Starting epoch 77\n",
            "time taken for epoch 77 is 12.89\n",
            "Starting epoch 78\n",
            "time taken for epoch 78 is 12.50\n",
            "Starting epoch 79\n",
            "time taken for epoch 79 is 12.70\n",
            "Starting epoch 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets the model in evaluation mode\n",
        "mlp.eval()\n",
        "train_mse=[]\n",
        "\n",
        "# Train dataset\n",
        "for input_batch, target_batch in train_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  train_mse.append(mse)\n",
        "\n",
        "\n",
        "print('Training:')\n",
        "print(f'Train MSE {np.mean(train_mse)}')\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "\n",
        "valid_mse=[]\n",
        "# Vaidation dataset\n",
        "for input_batch, target_batch in val_loader:\n",
        "  predict_batch = mlp(input_batch)\n",
        "  mse=mean_squared_error(predict_batch.flatten().tolist(), target_batch.tolist())\n",
        "  valid_mse.append(mse)\n",
        "\n",
        "print('Validation:')\n",
        "print(f'Validation MSE {np.mean(valid_mse)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GZkEWpixVoF",
        "outputId": "1fc49281-458e-48f6-88b0-b290cb9ca07b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Train MSE 11273.353606946099\n",
            "--------------------------------------------------\n",
            "Validation:\n",
            "Validation MSE 53967.017957855394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a custom class for test data"
      ],
      "metadata": {
        "id": "5nAl9sonwWQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset_test(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        \"\"\"\n",
        "        This is extraction step of the data processing\n",
        "        \"\"\"\n",
        "        file_out = pd.read_csv(filename)\n",
        "        x = file_out.iloc[:,:].values\n",
        "        sc = StandardScaler()\n",
        "        x =  sc.fit_transform(x)\n",
        "\n",
        "        \"\"\"\n",
        "        This is the transformation step of data\n",
        "        \"\"\"\n",
        "        self.X = torch.tensor(x, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DVCIjgREyB0v"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = CustomDataset_test('test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "321suZq-wl-m",
        "outputId": "462fb82c-9ad7-490d-92e0-9911103656d7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-9a11ae79d439>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.y = torch.tensor(y, dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset using data loader and making mini-batches\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_set,\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "WeKVhmlZyvcn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_batch in test_loader:\n",
        "  predict_batch_test = mlp(input_batch)"
      ],
      "metadata": {
        "id": "iXEZ9s8z0e_B"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_batch = torch.clamp(predict_batch, min=0)"
      ],
      "metadata": {
        "id": "UtS3jqrj0ssQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_batch"
      ],
      "metadata": {
        "id": "qCEOKegG05bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_batch_list = predict_batch.flatten().tolist()"
      ],
      "metadata": {
        "id": "-X7MrAcr1xw1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjUpaYHL3RWI",
        "outputId": "5e4bbd0a-1467-4dfa-b2a7-46b4ae8f65cd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7825"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_list=[]\n",
        "for x in range(len(test_set)):\n",
        "  test_list.append(test_set[x][0].tolist())"
      ],
      "metadata": {
        "id": "F2_TQRur12g0"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_list[1:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn7ylLeh4FRd",
        "outputId": "663c3b33-1bf1-4d85-f508-1c07ad8c18ec"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.8635117411613464,\n",
              " 1.7192877531051636,\n",
              " -1.0914406776428223,\n",
              " 0.1690276712179184]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.DataFrame(zip(test_list, predict_batch_list), columns=['Id','y'])"
      ],
      "metadata": {
        "id": "5_AXsbze37e0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv('final_df.csv',sep=',', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "hau6nlD_4OCR"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQegJAyA4RTM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}